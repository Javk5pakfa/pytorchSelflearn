{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Import modules",
   "id": "5f0ca09ad34c8bc3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from basic_FFN import get_batch_datasets\n",
    "from trial_encoding_block import TrialEncodingBlock\n",
    "from json import load\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "5e460f964e7af91b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load some data",
   "id": "909e3fe3ff736ed7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def process_nans(in_vec: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    *Assuming (Number of sources, number of rows in each source, sources size). This function gets rid of nan values and their positions from the data tensor.\n",
    "    \n",
    "    :param in_vec: torch.Tensor\n",
    "    :return: torch.Tensor\n",
    "    \"\"\"\n",
    "    \n",
    "    out_vec = []\n",
    "    for sub_vec in in_vec:\n",
    "        non_nan_indices = ~torch.isnan(sub_vec[1])\n",
    "        filtered_sub_vec = sub_vec[:, non_nan_indices]\n",
    "        out_vec.append(filtered_sub_vec)\n",
    "        \n",
    "    filtered_in_vec = torch.cat(out_vec, dim=1)\n",
    "    \n",
    "    return filtered_in_vec\n",
    "        "
   ],
   "id": "6875e518ac428339",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get raw datasets.\n",
    "train_ds = get_batch_datasets(0,\n",
    "                              800,\n",
    "                        \"agn_{}_synthetic.csv\",\n",
    "                        \"/Users/jackhu/PycharmProjects/pytorchSelflearn/data/agn_synthetic\")\n",
    "validate_ds = get_batch_datasets(800,\n",
    "                                 899,\n",
    "                             \"agn_{}_synthetic.csv\",\n",
    "                             \"/Users/jackhu/PycharmProjects/pytorchSelflearn/data/validate\")\n",
    "\n",
    "with open(\"/Users/jackhu/PycharmProjects/pytorchSelflearn/dataTransformer/trial_configs.json\", 'r') as f:\n",
    "    options = load(f)\n",
    "\n",
    "# Initialize transformer object, make dataset list a Tensor.\n",
    "train_ds_tensor = process_nans(torch.Tensor(np.array(train_ds)).requires_grad_(True))\n",
    "valid_ds_tensor = process_nans(torch.Tensor(np.array(validate_ds)).requires_grad_(True))\n",
    "\n",
    "# # Rework the training and validation tensors to only have the data dimension.\n",
    "# train_ds_tensor = train_ds_tensor[:, 1, :].unsqueeze(2)\n",
    "# valid_ds_tensor = valid_ds_tensor[:, 1, :].unsqueeze(2)\n",
    "\n",
    "train_dataset = TensorDataset(train_ds_tensor)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "valid_dataset = TensorDataset(valid_ds_tensor)\n",
    "valid_loader = DataLoader(dataset=valid_dataset, batch_size=10, shuffle=True)"
   ],
   "id": "994c2b2d7509e7d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_ds_tensor.size()",
   "id": "e407acc78c272a26",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Positional Encoder",
   "id": "5930649f36db7bc8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Positional Encoding Module\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        \"\"\"\n",
    "        \n",
    "        :param d_model: dimension of embedding.\n",
    "        :param max_len: maximum length of input sequence.\n",
    "        \"\"\"\n",
    "        super(PositionalEncoding, self).__init__()       \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        \"x\" is expected to be of size [seq_len, d_model].\n",
    "        :param x: embedded Tensor.\n",
    "        :return: Combined positional embedding Tensor.\n",
    "        \"\"\"\n",
    "        \n",
    "        return x + self.pe[:x.size(0), :]"
   ],
   "id": "5a671be350e9fc48",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Transformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer Module. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, **configs):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.__d_input = configs['input_dim']\n",
    "        self.__d_output = configs['output_dim']\n",
    "        self.__d_emb = configs['embed_dim']\n",
    "        self.__n_enc_layers = configs['encoder_layers']\n",
    "        \n",
    "        self.__model_type = 'Transformer'\n",
    "        self.__src_mask = None\n",
    "        self.__pos_enc = PositionalEncoding(self.__d_emb)\n",
    "        self.__ini_enc = nn.Embedding(self.__d_input, self.__d_emb)\n",
    "        \n",
    "        # My implementation of encoder.\n",
    "        self.__transformer_encoder = nn.ModuleList([TrialEncodingBlock(**configs) \n",
    "                                                    for _ in range(self.__n_enc_layers)])\n",
    "        \n",
    "        self.__encoder = nn.Linear(1, self.__d_emb)\n",
    "        self.__decoder = nn.Linear(self.__d_emb, self.__d_output)\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self, init_range=0.1):\n",
    "        self.__encoder.weight.data.uniform_(-init_range, init_range)\n",
    "        self.__decoder.weight.data.uniform_(-init_range, init_range)\n",
    "        \n",
    "    def forward(self, src, src_mask=None):\n",
    "        \"\"\"\n",
    "        \n",
    "        :param src: \n",
    "        :param src_mask: \n",
    "        :return: \n",
    "        \"\"\"\n",
    "        \n",
    "        if src_mask is None or src_mask.size(0) != src.size(1):\n",
    "            device = src.device\n",
    "            mask = self.__generate_mask(src.size(1)).to(device)\n",
    "            self.__src_mask = mask\n",
    "            \n",
    "        src = self.__encoder(src)\n",
    "        src = self.__pos_enc(src)\n",
    "        output = None\n",
    "        for layer in self.__transformer_encoder:\n",
    "            output = layer(src, self.__src_mask)\n",
    "        output = self.__decoder(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def __generate_mask(self, size):\n",
    "        mask = (torch.triu(torch.ones(size, size)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(\n",
    "            mask == 1, float(0.0))\n",
    "        return mask\n",
    "        \n",
    "# For debugging\n",
    "test_transform = Transformer(**options)\n",
    "test_transform.train()\n",
    "\n",
    "out = None\n",
    "for batch in train_loader:\n",
    "    batch_tensor = batch[0]\n",
    "    \n",
    "    out = test_transform.forward(batch_tensor)\n",
    "\n",
    "print(out.size())\n"
   ],
   "id": "aa354a9a0a4d46ff",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
